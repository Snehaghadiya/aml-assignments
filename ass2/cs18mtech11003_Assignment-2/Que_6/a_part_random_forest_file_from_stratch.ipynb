{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "from math import log\n",
    "from math import sqrt\n",
    "from random import randrange\n",
    "myname='sneha'\n",
    "txt_file = \"/home/sneha/Desktop/spam.txt\"\n",
    "csv_file = \"/home/sneha/Desktop/spam.csv\"\n",
    "in_txt = csv.reader(open(txt_file, \"rb\"), delimiter = ' ')\n",
    "out_csv = csv.writer(open(csv_file, 'wb'))\n",
    "out_csv.writerows(in_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    tree = {}\n",
    "    #gini index calculation function\n",
    "    def Gini(self,new_result):\n",
    "        if(len(new_result)==0):\n",
    "            return 0\n",
    "        count_0=float(new_result.count(0))/len(new_result)\n",
    "        count_1=float(new_result.count(1))/len(new_result)\n",
    "        r = 1-(count_0*count_0)-(count_1*count_1)\n",
    "        return r\n",
    "    #random colum selection\n",
    "    def colum_select(self,num_features):\n",
    "        new_col=[]\n",
    "        while len(new_col) <= num_features:\n",
    "            index = randrange(57)\n",
    "            if index not in new_col:\n",
    "                new_col.append(index)\n",
    "        return new_col\n",
    "    #random row selection\n",
    "    def subsample(self,train_set, ratio):\n",
    "        sample =[]\n",
    "        sample_index=[]\n",
    "        n_sample = int(train_set.shape[0] * ratio)\n",
    "        while len(sample) < n_sample:\n",
    "            index = randrange(len(train_set))\n",
    "            sample_index.append(index)\n",
    "            sample.append(train_set[index])\n",
    "        return np.array(sample),sample_index\n",
    "\n",
    "    #when only one colum left then it will return 0,if count of 0 is more in label otherwise one\n",
    "    def majorClass(self,col, train_set):\n",
    "        a=np.array([])    \n",
    "        if(train_set.shape==a.shape):\n",
    "            return 0\n",
    "        else:\n",
    "            result_train=train_set[:,-1]\n",
    "            result_train=list(result_train)\n",
    "\n",
    "            for i in result_train:\n",
    "                count_0=result_train.count(0)\n",
    "                count_1=result_train.count(1)\n",
    "                if(count_0>=count_1):\n",
    "                    return 0\n",
    "                else:\n",
    "                    return 1\n",
    "                \n",
    "    #This function return the max vaule in the colum divided by 10  \n",
    "    def Max(self,train_set,col):\n",
    "        max_val=np.amax(train_set,axis=0)\n",
    "        return max_val[col]/10\n",
    "        \n",
    "     #This function returns the best column which has highest information gain     \n",
    "    def BestCol(self,train_set,col):\n",
    "        col_num=13\n",
    "        result_train=train_set[:,-1]\n",
    "        train_set=train_set[:,:-1]\n",
    "        new_result=list(result_train)\n",
    "        gini_gain=0.0\n",
    "        val=np.amax(train_set,axis=0)\n",
    "        gini=DecisionTree.Gini(self,new_result)\n",
    "        left_rel=[]\n",
    "        right_rel=[]\n",
    "        for i in col:\n",
    "            count_left=0\n",
    "            count_right=0\n",
    "            left_result=[]\n",
    "            right_result=[]\n",
    "            for j in range(train_set.shape[0]):\n",
    "                if(train_set[j,i] <= val[i]/10):\n",
    "                    count_left=count_left+1\n",
    "                    left_result.append(result_train[j])\n",
    "                else:\n",
    "                    count_right=count_right+1\n",
    "                    right_result.append(result_train[j])\n",
    "        \n",
    "        \n",
    "            gini_1=(float(count_left)/len(new_result))*(DecisionTree.Gini(self,left_result))\n",
    "            gini_1=gini_1+(float(len(right_result))/len(new_result))*(DecisionTree.Gini(self,right_result))\n",
    "            \n",
    "        \n",
    "            gini_gain_test = float(gini)-gini_1\n",
    "            if( gini_gain_test >gini_gain ):\n",
    "                gini_gain=gini_gain_test\n",
    "                col_num=i\n",
    "                left_rel=left_result\n",
    "                right_rel=right_result\n",
    "\n",
    "        if(gini_gain_test==0):\n",
    "            return None\n",
    "        return col_num\n",
    "        \n",
    "    #this function returns the two numpy array i.e split of given numpy 'left and right'     \n",
    "    def Split(self,train_set,col_num,val):\n",
    "        right=[]\n",
    "        left=[]\n",
    "        for j in range(train_set.shape[0]):\n",
    "            if(train_set[j,col_num]<=val):\n",
    "                left.append(train_set[j])\n",
    "            else:\n",
    "                right.append(train_set[j])\n",
    "        right=np.array(right)\n",
    "        left=np.array(left)\n",
    "        return left,right\n",
    "     # this function forms the tree\n",
    "    def TreeForm(self,train_set,col):\n",
    "        tree={}\n",
    "        default = DecisionTree.majorClass(self,col, train_set)\n",
    "\n",
    "        \n",
    "        if not train_set.shape[0] or (len(col) - 1) <= 0:\n",
    "            return default\n",
    "        result_train=train_set[:,-1]\n",
    "        result_train=list(result_train)\n",
    "        count_0=result_train.count(0)\n",
    "        count_1=result_train.count(1)\n",
    "        if ( (count_0==len(result_train)) or (count_1==len(result_train)) ):\n",
    "            if(count_0>=count_1):\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "            \n",
    "        else:\n",
    "            best = DecisionTree.BestCol(self,train_set,col) \n",
    "            if(best==None):\n",
    "                return default\n",
    "            best_1=dic[best]\n",
    "            tree = {best_1: {}}\n",
    "            val=DecisionTree.Max(self,train_set,best)\n",
    "            new_dataleft,new_dataright = DecisionTree.Split(self,train_set,best, val)\n",
    "            newAttr = DecisionTree.colum_select(self,num_features)\n",
    "            sub1=DecisionTree.TreeForm(self,new_dataleft,newAttr)\n",
    "            sub2=DecisionTree.TreeForm(self,new_dataright,newAttr)\n",
    "            tree[best_1]['1']=sub1\n",
    "            tree[best_1]['2']=sub2\n",
    "            tree[best_1]['max']=val\n",
    "            return tree\n",
    "        \n",
    "    def learn(self, train_set,new_col):\n",
    "        self.tree=DecisionTree.TreeForm(self,train_set,new_col)\n",
    "     \n",
    "    \n",
    "    #Classify function for test data\n",
    "    def classify(self, test_instance, dict_3):\n",
    "        key_list=[]\n",
    "        for key in dict_3:\n",
    "            key_list.append(key)\n",
    "        s=key_list[0]\n",
    "        col_num = dic_test[s]\n",
    "        if( test_instance[col_num] <= dict_3[s]['max'] ):\n",
    "            t= dict_3[s]\n",
    "            if (type(t['1'])==type(0)):\n",
    "                return t['1']\n",
    "\n",
    "            else:\n",
    "                d=DecisionTree.classify(self,test_instance,t['1'])\n",
    "                return d\n",
    "        else:\n",
    "            t= dict_3[s]\n",
    "            if (type(t['2'])==type(0)):\n",
    "                return t['2']\n",
    "\n",
    "            else:\n",
    "                d= DecisionTree.classify(self,test_instance,t['2'])\n",
    "                return d\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def run_decision_tree(num):\n",
    "    tree = DecisionTree()\n",
    "    # random selection of colum\n",
    "    new_col=tree.colum_select(num_features)\n",
    "    # random selection of rows\n",
    "    sample,sample_index=tree.subsample(training_set,ratio)\n",
    "    train_sets_list.append(sample_index)\n",
    "    tree.learn(sample,new_col)\n",
    "    new_dic=tree.__dict__  \n",
    "    trees_in_dict[num]=new_dic['tree']\n",
    "    # Classify the test set using the tree we just constructed\n",
    "    results = []\n",
    "    for instance in test_set:\n",
    "        result = tree.classify(instance[:-1],new_dic['tree'] )  \n",
    "        results.append( result)\n",
    "    final_results.append(results) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9333\n",
      "('time_taken', 28.874829053878784)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    data = np.genfromtxt ('/home/sneha/Desktop/spam.csv', delimiter=\",\")\n",
    "    np.random.shuffle(data)\n",
    "    #Dividing the data into test and train\n",
    "    a=int(data.shape[0]*30/100)\n",
    "    test_set=data[:a]\n",
    "    training_set=data[a:]\n",
    "    train_sets_list=[]\n",
    "    trees_in_dict={}\n",
    "    final_results = []\n",
    "    colum=[]\n",
    "    ratio=0.8\n",
    "    num_of_trees=30\n",
    "    for i in range(57):\n",
    "        colum.append(i)\n",
    "    dic={}\n",
    "    dic_test={}\n",
    "    for i in range(57):\n",
    "        dic[i]=str(i)\n",
    "        dic_test[str(i)]=i\n",
    "    num_features=15\n",
    "    for i in range(num_of_trees):\n",
    "        run_decision_tree(i)\n",
    "    final_results=np.array(final_results)\n",
    "    final_results=list(np.sum(final_results,axis=0))\n",
    "    result=[]\n",
    "    #Comparing the predicted result with actual result\n",
    "    for i in range(len(final_results)):\n",
    "        if(final_results[i]>(num_of_trees-final_results[i])):\n",
    "            final_results[i]=1\n",
    "            result.append( final_results[i] == (test_set[i][-1]))\n",
    "            \n",
    "        else:\n",
    "            final_results[i]=0\n",
    "            result.append( final_results[i] == (test_set[i][-1]))\n",
    "    # Accuracy\n",
    "    accuracy = float(result.count(True))/float(len(final_results))\n",
    "    print \"accuracy: %.4f\" % accuracy \n",
    "    end = time.time()\n",
    "    print('time_taken', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
