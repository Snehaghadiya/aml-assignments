{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CS6510 HW 1 Code Skeleton\n",
    "# Please use this outline to implement your decision tree. You can add any code around this.\n",
    "\n",
    "import csv\n",
    "\n",
    "# Enter You Name Here\n",
    "myname = \"Sneha-Ghadiya\" # or \"Doe-Jane-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    tree = {}\n",
    "    \n",
    "    #Entropy calculation function\n",
    "    def Entropy(self,new_result):\n",
    "        if(len(new_result)==0):\n",
    "            return 0;\n",
    "            \n",
    "        count_0=float(new_result.count(0))/len(new_result)\n",
    "        count_1=float(new_result.count(1))/len(new_result)\n",
    "        if(count_0==0 or count_1==0):\n",
    "            return 0\n",
    "        else:\n",
    "            x1=count_0*(math.log(count_0,2))\n",
    "            x2=count_1*(math.log(count_1,2))\n",
    "            entropy=(-1)*(x1+x2)\n",
    "            return entropy\n",
    "    #when only one colum left then it will return 0,if count of 0 is more in label otherwise one\n",
    "    def majorClass(self,col, train_set):\n",
    "        a=np.array([])\n",
    "        if(train_set.shape==a.shape):\n",
    "            return 0\n",
    "        else:\n",
    "            result_train=train_set[:,-1]\n",
    "            result_train=list(result_train)\n",
    "\n",
    "            for i in result_train:\n",
    "                count_0=result_train.count(0)\n",
    "                count_1=result_train.count(1)\n",
    "                if(count_0>=count_1):\n",
    "                    return 0\n",
    "                else:\n",
    "                    return 1\n",
    "    #This function return the max vaule in the colum divided by 10  \n",
    "    def Max(self,train_set,col):\n",
    "        max_val=np.amax(train_set,axis=0)\n",
    "        return max_val[col]/10\n",
    "        \n",
    "    #This function returns the best column which has highest information gain    \n",
    "    def BestCol(self,train_set,col):\n",
    "        col_num=13\n",
    "        result_train=train_set[:,-1]\n",
    "        train_set=train_set[:,:-1]\n",
    "        new_result=list(result_train)\n",
    "        info_gain=0.0\n",
    "        val=np.amax(train_set,axis=0)\n",
    "        entropy=DecisionTree.Entropy(self,new_result)\n",
    "        left_rel=[]\n",
    "        right_rel=[]\n",
    "        for i in col:\n",
    "            count_left=0\n",
    "            count_right=0\n",
    "            left_result=[]\n",
    "            right_result=[]\n",
    "            for j in range(train_set.shape[0]):\n",
    "                if(train_set[j,i] <= val[i]/10):\n",
    "                    count_left=count_left+1\n",
    "                    left_result.append(result_train[j])\n",
    "                else:\n",
    "                    count_right=count_right+1\n",
    "                    right_result.append(result_train[j])\n",
    "            entropy_1=(float(count_left)/len(new_result))*(DecisionTree.Entropy(self,left_result))\n",
    "            entropy_1=entropy_1+(float(len(right_result))/len(new_result))*(DecisionTree.Entropy(self,right_result))\n",
    "            info_gain_test = float(entropy)-entropy_1\n",
    "            if( (info_gain_test >= info_gain) ):\n",
    "                info_gain=info_gain_test\n",
    "                col_num=i\n",
    "                left_rel=left_result\n",
    "                right_rel=right_result\n",
    "        return col_num\n",
    "        \n",
    "    #this function returns the two numpy array i.e split of given numpy 'left and right'    \n",
    "    def Split(self,train_set,col_num,val):\n",
    "        right=[]\n",
    "        left=[]\n",
    "        for j in range(train_set.shape[0]):\n",
    "            if(train_set[j,col_num]<=val):\n",
    "                left.append(train_set[j])\n",
    "            else:\n",
    "                right.append(train_set[j])\n",
    "        right=np.array(right)\n",
    "        left=np.array(left)\n",
    "        return left,right\n",
    "    # this function forms the tree\n",
    "    def TreeForm(self,train_set,col):\n",
    "        tree={}\n",
    "        default = DecisionTree.majorClass(self,col, train_set)\n",
    "        \n",
    "        if not train_set.shape[0] or (len(col) - 1) <= 0:\n",
    "            return default\n",
    "        result_train=train_set[:,-1]\n",
    "        result_train=list(result_train)\n",
    "        count_0=result_train.count(0)\n",
    "        count_1=result_train.count(1)\n",
    "        if ( (count_0==len(result_train)) or (count_1==len(result_train)) ):\n",
    "            if(count_0>=count_1):\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "            \n",
    "        else:\n",
    "            best = DecisionTree.BestCol(self,train_set,col)  \n",
    "            best_1=dic[best]\n",
    "            tree = {best_1: {}}\n",
    "            val=DecisionTree.Max(self,train_set,best)\n",
    "            new_dataleft,new_dataright = DecisionTree.Split(self,train_set,best, val)\n",
    "            newAttr = col[:]\n",
    "            newAttr.remove(best)\n",
    "            sub1=DecisionTree.TreeForm(self,new_dataleft,newAttr)\n",
    "            sub2=DecisionTree.TreeForm(self,new_dataright,newAttr)\n",
    "            tree[best_1]['1']=sub1\n",
    "            tree[best_1]['2']=sub2\n",
    "            tree[best_1]['max']=val\n",
    "            return tree\n",
    "        \n",
    "    def learn(self, train_set,new_col):\n",
    "        self.tree=DecisionTree.TreeForm(self,train_set,new_col)\n",
    "        \n",
    "    def classify(self, test_instance, dict_3):\n",
    "        key_list=[]\n",
    "        for key in dict_3:\n",
    "            key_list.append(key)\n",
    "        s=key_list[0]\n",
    "        col_num = dic_test[s]\n",
    "        if( test_instance[col_num] <= dict_3[s]['max'] ):\n",
    "            t= dict_3[s]\n",
    "            if (type(t['1'])==type(0)):\n",
    "                return t['1']\n",
    "\n",
    "            else:\n",
    "                d=DecisionTree.classify(self,test_instance,t['1'])\n",
    "                return d\n",
    "        else:\n",
    "            t= dict_3[s]\n",
    "            if (type(t['2'])==type(0)):\n",
    "                return t['2']\n",
    "\n",
    "            else:\n",
    "                d= DecisionTree.classify(self,test_instance,t['2'])\n",
    "                return d\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def run_decision_tree():\n",
    "    data = np.genfromtxt ('/home/sneha/Downloads/wine-dataset.csv', delimiter=\",\")\n",
    "    data=data[1:]\n",
    "    \n",
    "    c=0\n",
    "    d=0\n",
    "    d=data.shape[0]/10\n",
    "    for i in range(10):\n",
    "        s=data\n",
    "        test_set=data[c:c+d]\n",
    "        li=[]\n",
    "        for u in range(c,c+d):\n",
    "            li.append(u)\n",
    "        training_set=np.delete(s,li,axis=0)\n",
    "        c=c+d\n",
    "        tree = DecisionTree()\n",
    "    \n",
    "    # Construct a tree using training set\n",
    "        tree.learn(training_set,colum)\n",
    "        new_dic=tree.__dict__\n",
    "        \n",
    "    # Classify the test set using the tree we just constructed\n",
    "        results = []\n",
    "        for instance in test_set:\n",
    "            result = tree.classify(instance[:-1],new_dic['tree'] )\n",
    "            \n",
    "            results.append( result == (instance[-1]))\n",
    "        \n",
    "    # Accuracy\n",
    "        accuracy = float(results.count(True))/float(len(results))\n",
    "        print \"accuracy: %.4f\" % accuracy       \n",
    "    \n",
    "    # Writing results to a file (DO NOT CHANGE)\n",
    "        f = open(myname+\"result.txt\", \"w\")\n",
    "        f.write(\"accuracy: %.4f\" % accuracy)\n",
    "        f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8078\n",
      "accuracy: 0.7362\n",
      "accuracy: 0.7505\n",
      "accuracy: 0.8221\n",
      "accuracy: 0.8691\n",
      "accuracy: 0.7526\n",
      "accuracy: 0.7157\n",
      "accuracy: 0.7342\n",
      "accuracy: 0.8160\n",
      "accuracy: 0.8303\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    colum=[0,1,2,3,4,5,6,7,8,9,10]\n",
    "    dic={0:'fixed acidity',1: 'volatile acidity',2:'citric acid',3:'residual sugar', 4:'chlorides', 5:'free sulfur dioxide', 6:'total sulfur dioxide', 7:'density', 8:'pH', 9:'sulphates', 10:'alcohol'}\n",
    "    dic_test={'fixed acidity':0,'volatile acidity':1,'citric acid':2,'residual sugar':3, 'chlorides':4,'free sulfur dioxide':5, 'total sulfur dioxide':6, 'density':7, 'pH':8, 'sulphates':9, 'alcohol':10 }\n",
    "    \n",
    "    run_decision_tree()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
