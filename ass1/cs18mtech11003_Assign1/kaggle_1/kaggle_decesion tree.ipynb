{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sneha/miniconda3/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#import the library\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#load the training set\n",
    "import json\n",
    "with open('/home/sneha/Downloads/kaggle/train.json') as json_file:  \n",
    "    data = json.load(json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a list having ingredients and, ingredients of different ids are comma seperated \"making data compatible for count vector\"\n",
    "x=[]\n",
    "for i in data:\n",
    "    strf=''\n",
    "    for j in i['ingredients']:\n",
    "        if(strf==''):\n",
    "            strf=strf+j\n",
    "        else:\n",
    "            strf=strf+' '+j\n",
    "    x.append(strf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making count vector of training dataset\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making list of labels\n",
    "X=X.toarray()\n",
    "y=[]\n",
    "for i in data:\n",
    "    y.append(i['cuisine'])\n",
    "y=np.array(y)\n",
    "Y=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3, random_state = 100)\n",
    "clf_gini = DecisionTreeClassifier( random_state = 100,\n",
    "                               max_depth=200, min_samples_leaf=5)\n",
    "clf_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the names of columns\n",
    "col=vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making list of ids\n",
    "id=[]\n",
    "for i in data:\n",
    "    id.append(i['id'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making list of numbers from 0 to 9944 which is the count of rows of test data\n",
    "kp=[]\n",
    "for i in range(9944):\n",
    "    kp.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making empty data frame so as to store the bit vector of test data\n",
    "df=pd.DataFrame(columns=col,index=kp,data=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the test data\n",
    "with open('/home/sneha/Downloads/kaggle/test.json') as json_file:  \n",
    "    data_test = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the ingredients in training get split like  baking powder 'baking is a different colum and powder is different' so in test data also we are spliting\n",
    "l=0\n",
    "for i in data_test:\n",
    "    for j in i['ingredients']:\n",
    "        d=j.split()\n",
    "        for v in d:\n",
    "            t=col.count(v)\n",
    "            if(t>0):\n",
    "                df[v][l]=1\n",
    "            elif(t>0):\n",
    "                df[v][l]=0\n",
    "    l=l+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=np.array(df)\n",
    "f=clf_gini.predict(df)\n",
    "f=list(f)\n",
    "h=f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the test ids\n",
    "test_id=[]\n",
    "for i in data_test:\n",
    "    test_id.append(i['id'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the labels in a csv file\n",
    "import csv\n",
    "from itertools import izip\n",
    "\n",
    "with open('i_m_in.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(izip(test_id, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
